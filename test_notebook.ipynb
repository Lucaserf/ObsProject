{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-30 09:33:57.548139: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-11-30 09:33:57.577153: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-30 09:33:57.577176: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-30 09:33:57.577195: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-30 09:33:57.582632: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.dont_write_bytecode = True\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import bz2\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import marshal\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend\n"
     ]
    }
   ],
   "source": [
    "from docker_agent_logger.app.src.AI import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-30 09:34:07.536559: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22312 MB memory:  -> device: 0, name: NVIDIA RTX A5000, pci bus id: 0000:b3:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "raw_ds = ( #.filter(lambda x: tf.strings.length(x) > MIN_TRAINING_SEQ_LEN)\n",
    "    tf.data.TextLineDataset(\"persistent_volume/data/HDFS_v1/HDFS.log\")\n",
    "    # .batch(128)\n",
    "    # .shuffle(buffer_size=256)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in raw_ds.take(100):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i in raw_ds.batch(128):\n",
    "    count += 128\n",
    "\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get max len, mean len and std len excluding outliers (len > 1000)\n",
    "seq_lens = []\n",
    "for i in raw_ds:\n",
    "    seq_lens.append(len(i.numpy()))\n",
    "    if len(i.numpy()) > 1000:\n",
    "        print(len(i.numpy()))\n",
    "\n",
    "seq_lens = np.array(seq_lens)\n",
    "print(seq_lens.max())\n",
    "print(seq_lens.mean())\n",
    "print(seq_lens.std())\n",
    "print(seq_lens.min())\n",
    "print(len(seq_lens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_word_ids (InputLayer  [(None, 60)]                 0         []                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " input_embedding (TokenAndP  (None, 60, 128)              391680    ['input_word_ids[0][0]']      \n",
      " ositionEmbedding)                                                                                \n",
      "                                                                                                  \n",
      " encoding (TransformerEncod  (None, 60, 128)              74398     ['input_embedding[0][0]']     \n",
      " er)                                                                                              \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem (  (None, 128)                  0         ['encoding[0][0]']            \n",
      " SlicingOpLambda)                                                                                 \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_1  (None, 128)                  0         ['encoding[0][0]']            \n",
      "  (SlicingOpLambda)                                                                               \n",
      "                                                                                                  \n",
      " z_mean (Dense)              (None, 30)                   3870      ['tf.__operators__.getitem[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " z_log_var (Dense)           (None, 30)                   3870      ['tf.__operators__.getitem_1[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " z (Sampling)                (None, 30)                   0         ['z_mean[0][0]',              \n",
      "                                                                     'z_log_var[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 473818 (1.81 MB)\n",
      "Trainable params: 473818 (1.81 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " latent_space_input (InputL  [(None, 60, 30)]          0         \n",
      " ayer)                                                           \n",
      "                                                                 \n",
      " hidden_layer (Dense)        (None, 60, 30)            930       \n",
      "                                                                 \n",
      " output (Dense)              (None, 60, 3000)          93000     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 93930 (366.91 KB)\n",
      "Trainable params: 93930 (366.91 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 3000\n",
    "max_len=60\n",
    "epochs=32\n",
    "chkpt = \"docker_agent_logger/app/classifier_labeled/31\"\n",
    "MIN_TRAINING_SEQ_LEN = 1000\n",
    "\n",
    "raw_ds = (\n",
    "    tf.data.TextLineDataset(\"persistent_volume/data/HDFS_v1/HDFS.log\")\n",
    "    .filter(lambda x: tf.strings.length(x) > MIN_TRAINING_SEQ_LEN)\n",
    "    # .batch(128)\n",
    "    # .shuffle(buffer_size=256)\n",
    ")\n",
    "\n",
    "# vocab = keras_nlp.tokenizers.compute_word_piece_vocabulary(\n",
    "#             raw_ds,\n",
    "#             vocabulary_size=vocab_size,\n",
    "#             reserved_tokens=[\"[PAD]\", \"[UNK]\", \"[BOS]\",\"[EOS]\"],\n",
    "#         )\n",
    "\n",
    "# with open(\"docker_agent_logger/app/logs_tokenizer/vocab.pkl\",\"wb\") as f:\n",
    "#     pickle.dump(vocab,f)\n",
    "\n",
    "with open(\"docker_agent_logger/app/logs_tokenizer/vocab_labeled.pkl\",\"rb\") as f:\n",
    "    vocab = pickle.load(f)\n",
    "\n",
    "tokenizer = Tokenizer(vocab=vocab,max_len=max_len)\n",
    "\n",
    "\n",
    "ds = raw_ds.map(tokenizer.preprocess, num_parallel_calls=tf.data.AUTOTUNE).prefetch(\n",
    "    tf.data.AUTOTUNE\n",
    ")\n",
    "\n",
    "\n",
    "val_split = 0.2\n",
    "ds_size = 11175629\n",
    "\n",
    "train_size = int((1-val_split) * ds_size)\n",
    "val_size = int(val_split * ds_size)\n",
    "\n",
    "train_ds = ds.take(train_size).shuffle(buffer_size=train_size).batch(128)\n",
    "val_ds = raw_ds.skip(train_size).take(val_size)\n",
    "\n",
    "\n",
    "\n",
    "model = Model(vocab_size = vocab_size,latent_dim=max_len//2,embedding_dim=128,max_len = max_len)\n",
    "\n",
    "model.vae.load_model(chkpt=chkpt) #17 for the other model\n",
    "\n",
    "# model.train_model(ds,epochs=epochs,chkpt=chkpt)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from docker_agent_reader.app.src.AI_rnd import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentile = 98\n",
    "anomaly_detector = AnomalyDetector(latent_space_dim=max_len//2,threshold=np.inf)\n",
    "data = {\"logs\":[],\"parsed_logs\":[],\"vectorized_logs\":[],\"encoded_logs\":[]}\n",
    "times = {\"parsed_logs\":[],\"vectorized_logs\":[],\"encoded_logs\":[],\"anomaly\":[],\"anomaly_rnd\":[]}\n",
    "recostruction_loss = []\n",
    "recostruction_loss_rnd = []\n",
    "d = collections.deque(maxlen=1000)\n",
    "d_rnd = collections.deque(maxlen=1000)\n",
    "thresholds = [np.inf,]\n",
    "thresholds_rnd = [np.inf,]\n",
    "\n",
    "\n",
    "for logs in val_ds.take(5000).batch(1):\n",
    "    t = time.time()\n",
    "    parsed_logs = tokenizer.parsing(logs)   \n",
    "    t_parse = time.time()\n",
    "    times[\"parsed_logs\"].append(t_parse-t)\n",
    "    vectorized_logs = tokenizer.vectorization(parsed_logs)\n",
    "    t_vectorize = time.time()\n",
    "    times[\"vectorized_logs\"].append(t_vectorize-t_parse)\n",
    "    encoded_logs = model.vae.encode(vectorized_logs)\n",
    "    t_encode = time.time()\n",
    "    times[\"encoded_logs\"].append(t_encode-t_vectorize)\n",
    "    losses = model.vae.train_step(vectorized_logs,train=False)\n",
    "\n",
    "\n",
    "    anomaly = False\n",
    "    if losses[\"reconstruction_loss\"].numpy() > thresholds[-1]:\n",
    "        anomaly = True\n",
    "        # print(f\"anomaly detected with a reconstruction loss of {losses['reconstruction_loss'].numpy()}\")\n",
    "\n",
    "    d.append(losses[\"reconstruction_loss\"].numpy())\n",
    "    thresholds.append(np.percentile(d,percentile))\n",
    "    \n",
    "    t_anomaly = time.time()\n",
    "    times[\"anomaly\"].append(t_anomaly-t_encode)\n",
    "\n",
    "    recostruction_loss_rnd_value, anomaly_rnd = anomaly_detector.detect(encoded_logs,thresholds_rnd[-1])\n",
    "\n",
    "    if anomaly_rnd:\n",
    "        print(f\"anomaly detected with a reconstruction loss of {recostruction_loss_rnd_value.numpy()}\")\n",
    "        print(logs.numpy()[0].decode(\"utf-8\"))\n",
    "\n",
    "    d_rnd.append(recostruction_loss_rnd_value.numpy())\n",
    "    thresholds_rnd.append(np.percentile(d_rnd,percentile))\n",
    "    \n",
    "\n",
    "    times[\"anomaly_rnd\"].append(time.time()-t_anomaly)\n",
    "\n",
    "    anomaly_detector.train_step(encoded_logs)\n",
    "\n",
    "\n",
    "    recostruction_loss_rnd.append(recostruction_loss_rnd_value.numpy())\n",
    "    recostruction_loss.append(losses[\"reconstruction_loss\"].numpy())\n",
    "    compressed_data = bz2.compress(pickle.dumps(logs))\n",
    "    data[\"logs\"].append(sys.getsizeof(compressed_data))\n",
    "    compressed_data = bz2.compress(pickle.dumps(parsed_logs))\n",
    "    data[\"parsed_logs\"].append(sys.getsizeof(compressed_data))\n",
    "    compressed_data = bz2.compress(pickle.dumps(vectorized_logs))\n",
    "    data[\"vectorized_logs\"].append(sys.getsizeof(compressed_data))\n",
    "    compressed_data = bz2.compress(pickle.dumps(encoded_logs))\n",
    "    data[\"encoded_logs\"].append(sys.getsizeof(compressed_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "for key in data.keys():\n",
    "    ax.plot(data[key], label=key)\n",
    "    plt.xlabel('logs')\n",
    "    plt.ylabel('size [Bytes]')\n",
    "    plt.legend()\n",
    "\n",
    "fig.savefig(\"data/size.png\")\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "for key in times.keys():\n",
    "    ax.plot(np.array(times[key][10:])*10**3, label=key)\n",
    "    plt.xlabel('logs')\n",
    "    plt.ylabel('time [ms]')\n",
    "    plt.legend()\n",
    "\n",
    "fig.savefig(\"data/time.png\")\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(thresholds)\n",
    "ax.plot(recostruction_loss)\n",
    "plt.xlabel('logs')\n",
    "plt.ylabel('reconstruction loss')\n",
    "\n",
    "fig.savefig(\"data/reconstruction_loss.png\")\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(thresholds_rnd)\n",
    "ax.plot(recostruction_loss_rnd)\n",
    "plt.xlabel('logs')\n",
    "plt.ylabel('reconstruction loss rnd')\n",
    "\n",
    "plt.savefig(\"data/reconstruction_loss_rnd.png\")\n",
    "\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z = tf.random.normal(shape=(1,60 ,30),dtype=tf.float32)\n",
    "encode_token = val_ds.take(1).batch(1).as_numpy_iterator().next()\n",
    "\n",
    "print(encode_token)\n",
    "\n",
    "\n",
    "z = model.vae.encoder(tokenizer.preprocess(encode_token))[0]\n",
    "\n",
    "tokens = model.vae.decode(z)\n",
    "\n",
    "print((tokenizer.decode(tokens).numpy()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_label_clusters(vae, name,data):\n",
    "    # display a 2D plot of the digit classes in the latent space\n",
    "    z_mean, _, _ = vae.encoder.predict(data)\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    plt.scatter(z_mean[:, 0], z_mean[:, 1])\n",
    "    plt.colorbar()\n",
    "    plt.xlabel(\"z[0]\")\n",
    "    plt.ylabel(\"z[1]\")\n",
    "    # plt.savefig(\"./results/\"+name+\".png\")\n",
    "    plt.show()\n",
    "\n",
    "# model = Model(vocab_size = vocab_size,latent_dim=256,embedding_dim=128,max_len = max_len)\n",
    "\n",
    "\n",
    "# for i in range(32):\n",
    "#     model.vae.load_model(chkpt=chkpt+str(i))\n",
    "\n",
    "#     plot_label_clusters(model.vae, \"cluster\"+str(i),ds)\n",
    "\n",
    "ds_val_pre = val_ds.map(tokenizer.preprocess, num_parallel_calls=tf.data.AUTOTUNE).prefetch(\n",
    "    tf.data.AUTOTUNE\n",
    ")\n",
    "\n",
    "plot_label_clusters(model.vae, \"cluster\"+str(17),ds_val_pre.take(10000).batch(128))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "obs-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
