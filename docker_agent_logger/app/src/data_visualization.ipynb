{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-15 13:33:30.485572: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-15 13:33:30.485641: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-15 13:33:30.498464: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-15 13:33:32.269414: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.dont_write_bytecode = True\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import bz2\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.chdir('/mnt/c/Users/ADMIN/github/ObsProject/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend\n"
     ]
    }
   ],
   "source": [
    "from AI import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_word_ids (InputLayer  [(None, 256)]                0         []                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " input_embedding (TokenAndP  (None, 256, 128)             672768    ['input_word_ids[0][0]']      \n",
      " ositionEmbedding)                                                                                \n",
      "                                                                                                  \n",
      " encoding (TransformerEncod  (None, 256, 128)             132480    ['input_embedding[0][0]']     \n",
      " er)                                                                                              \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_1  (None, 128)                  0         ['encoding[0][0]']            \n",
      " 0 (SlicingOpLambda)                                                                              \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_1  (None, 128)                  0         ['encoding[0][0]']            \n",
      " 1 (SlicingOpLambda)                                                                              \n",
      "                                                                                                  \n",
      " z_mean (Dense)              (None, 256)                  33024     ['tf.__operators__.getitem_10[\n",
      "                                                                    0][0]']                       \n",
      "                                                                                                  \n",
      " z_log_var (Dense)           (None, 256)                  33024     ['tf.__operators__.getitem_11[\n",
      "                                                                    0][0]']                       \n",
      "                                                                                                  \n",
      " z (Sampling)                (None, 256)                  0         ['z_mean[0][0]',              \n",
      "                                                                     'z_log_var[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 871296 (3.32 MB)\n",
      "Trainable params: 871296 (3.32 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " latent_space_input (InputL  [(None, 256, 256)]        0         \n",
      " ayer)                                                           \n",
      "                                                                 \n",
      " hidden_layer (Dense)        (None, 256, 256)          65792     \n",
      "                                                                 \n",
      " output (Dense)              (None, 256, 5000)         1285000   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1350792 (5.15 MB)\n",
      "Trainable params: 1350792 (5.15 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__Multinomial_device_/job:localhost/replica:0/task:0/device:GPU:0}} logits should be a matrix, got shape [1,256,5000] [Op:Multinomial] name: ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m/mnt/c/Users/ADMIN/github/ObsProject/docker_agent_logger/app/src/data_visualization.ipynb Cell 3\u001b[0m line \u001b[0;36m8\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/ADMIN/github/ObsProject/docker_agent_logger/app/src/data_visualization.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=79'>80</a>\u001b[0m z \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mnormal(shape\u001b[39m=\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39m256\u001b[39m))\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/ADMIN/github/ObsProject/docker_agent_logger/app/src/data_visualization.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=80'>81</a>\u001b[0m \u001b[39m# encode_token = ds.take(1).as_numpy_iterator().next()\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/ADMIN/github/ObsProject/docker_agent_logger/app/src/data_visualization.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=81'>82</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/ADMIN/github/ObsProject/docker_agent_logger/app/src/data_visualization.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=82'>83</a>\u001b[0m \u001b[39m# print(tokenizer.decode(encode_token))\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/ADMIN/github/ObsProject/docker_agent_logger/app/src/data_visualization.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=84'>85</a>\u001b[0m tokens \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mvae\u001b[39m.\u001b[39;49mdecode(z)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/ADMIN/github/ObsProject/docker_agent_logger/app/src/data_visualization.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=86'>87</a>\u001b[0m \u001b[39mprint\u001b[39m(tokenizer\u001b[39m.\u001b[39mdecode(tokens))\n",
      "File \u001b[0;32m/mnt/c/Users/ADMIN/github/ObsProject/docker_agent_logger/app/src/AI.py:194\u001b[0m, in \u001b[0;36mVAE.decode\u001b[0;34m(self, z)\u001b[0m\n\u001b[1;32m    192\u001b[0m logits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecoder(z)\n\u001b[1;32m    193\u001b[0m \u001b[39m# reconstruction = tf.argmax(logits,axis=-1)\u001b[39;00m\n\u001b[0;32m--> 194\u001b[0m reconstruction \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mrandom\u001b[39m.\u001b[39;49mcategorical(logits\u001b[39m=\u001b[39;49mlogits,num_samples\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m    195\u001b[0m \u001b[39mreturn\u001b[39;00m reconstruction\n",
      "File \u001b[0;32m/mnt/c/Users/ADMIN/virtualenvs/obs-env/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/mnt/c/Users/ADMIN/virtualenvs/obs-env/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:5888\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   5886\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mraise_from_not_ok_status\u001b[39m(e, name) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m NoReturn:\n\u001b[1;32m   5887\u001b[0m   e\u001b[39m.\u001b[39mmessage \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39m name: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(name \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[0;32m-> 5888\u001b[0m   \u001b[39mraise\u001b[39;00m core\u001b[39m.\u001b[39m_status_to_exception(e) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__Multinomial_device_/job:localhost/replica:0/task:0/device:GPU:0}} logits should be a matrix, got shape [1,256,5000] [Op:Multinomial] name: "
     ]
    }
   ],
   "source": [
    "# df = pd.read_csv(\"docker_agent_logger/app/data/OpenStack_2k.log_structured.csv\")\n",
    "\n",
    "# labels = tf.constant(df[\"EventId\"].apply(lambda x: int(x[1:])-1))\n",
    "\n",
    "# df = df.drop([\"LineId\",\"EventId\",\"EventTemplate\"],axis=1)\n",
    "\n",
    "# df[\"Pid\"] = df[\"Pid\"].apply(str)\n",
    "\n",
    "# logs = []\n",
    "\n",
    "# for i,r in df.iterrows():\n",
    "#     logs.append(\" \".join(r))\n",
    "\n",
    "\n",
    "\n",
    "vocab_size = 5000\n",
    "max_len=256\n",
    "epochs=32\n",
    "chkpt = \"docker_agent_logger/app/classifier/\"\n",
    "\n",
    "raw_ds = ( #.filter(lambda x: tf.strings.length(x) > MIN_TRAINING_SEQ_LEN)\n",
    "    tf.data.TextLineDataset(\"docker_agent_logger/app/data/HDFS_v2/node_logs/hadoop-hdfs-datanode-mesos-32.log\")\n",
    "    .batch(32)\n",
    "    .shuffle(buffer_size=256)\n",
    ")\n",
    "\n",
    "# vocab = keras_nlp.tokenizers.compute_word_piece_vocabulary(\n",
    "#             raw_ds,\n",
    "#             vocabulary_size=vocab_size,\n",
    "#             reserved_tokens=[\"[PAD]\", \"[UNK]\", \"[BOS]\",\"[EOS]\"],\n",
    "#         )\n",
    "\n",
    "# with open(\"docker_agent_logger/app/logs_tokenizer/vocab.pkl\",\"wb\") as f:\n",
    "#     pickle.dump(vocab,f)\n",
    "\n",
    "with open(\"docker_agent_logger/app/logs_tokenizer/vocab.pkl\",\"rb\") as f:\n",
    "    vocab = pickle.load(f)\n",
    "\n",
    "tokenizer = Tokenizer(vocab=vocab,max_len=max_len)\n",
    "\n",
    "\n",
    "ds = raw_ds.map(tokenizer.preprocess, num_parallel_calls=tf.data.AUTOTUNE).prefetch(\n",
    "    tf.data.AUTOTUNE\n",
    ")\n",
    "\n",
    "# val_split = 0.2\n",
    "# ds_size = ds.cardinality().numpy()\n",
    "\n",
    "# train_size = int((1-val_split) * ds_size)\n",
    "# val_size = int(val_split * ds_size)\n",
    "\n",
    "# train_ds = ds.take(train_size)\n",
    "# val_ds = ds.skip(train_size).take(val_size)\n",
    "\n",
    "\n",
    "\n",
    "model = Model(vocab_size = vocab_size,latent_dim=256,embedding_dim=128,max_len = max_len)\n",
    "\n",
    "model.vae.load_model(chkpt=chkpt)\n",
    "\n",
    "# model.train_model(ds,epochs=epochs,chkpt=chkpt)\n",
    "\n",
    "\n",
    "\n",
    "# def plot_label_clusters(vae, data):\n",
    "#     # display a 2D plot of the digit classes in the latent space\n",
    "#     z_mean, _, _ = vae.encoder.predict(data)\n",
    "#     plt.figure(figsize=(12, 10))\n",
    "#     plt.scatter(z_mean[:, 0], z_mean[:, 1])\n",
    "#     plt.colorbar()\n",
    "#     plt.xlabel(\"z[0]\")\n",
    "#     plt.ylabel(\"z[1]\")\n",
    "#     plt.savefig(\"cluster.png\")\n",
    "\n",
    "# plot_label_clusters(model.vae, ds)\n",
    "\n",
    "z = tf.random.normal(shape=(1, 256))\n",
    "# encode_token = ds.take(1).as_numpy_iterator().next()\n",
    "\n",
    "# print(tokenizer.decode(encode_token))\n",
    "\n",
    "tokens = model.vae.decode(z)\n",
    "\n",
    "print(tokenizer.decode(tokens))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_label_clusters(vae, name,data):\n",
    "    # display a 2D plot of the digit classes in the latent space\n",
    "    z_mean, _, _ = vae.encoder.predict(data)\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    plt.scatter(z_mean[:, 0], z_mean[:, 1])\n",
    "    plt.colorbar()\n",
    "    plt.xlabel(\"z[0]\")\n",
    "    plt.ylabel(\"z[1]\")\n",
    "    plt.savefig(\"./results/\"+name+\".png\")\n",
    "    plt.show()\n",
    "\n",
    "model = Model(vocab_size = vocab_size,latent_dim=256,embedding_dim=128,max_len = max_len)\n",
    "\n",
    "\n",
    "for i in range(32):\n",
    "    model.vae.load_model(chkpt=chkpt+str(i))\n",
    "\n",
    "    plot_label_clusters(model.vae, \"cluster\"+str(i),ds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "obs-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
